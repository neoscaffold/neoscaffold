{"last_node_id":163,"last_link_id":225,"nodes":[{"id":99,"type":"nsInteger","pos":[-412,485],"size":{"0":210,"1":140},"flags":{},"order":0,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[92],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"99","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"99","values":12,"cacheable":true},"timestamp":"12/16/24, 09:01:49.965 PM"}},"widgets_values":[12,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":93,"type":"PassThrough","pos":[-134,454],"size":{"0":210,"1":185},"flags":{},"order":11,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":92},{"name":"ignored_input","type":"*","link":78}],"outputs":[{"name":"*","type":"*","links":[93],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"93","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"93","values":12,"cacheable":true},"timestamp":"12/16/24, 09:01:50.568 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":79,"type":"nsInteger","pos":[-411,747],"size":{"0":210,"1":140},"flags":{},"order":1,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[94],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"79","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"79","values":6,"cacheable":true},"timestamp":"12/16/24, 09:01:49.557 PM"}},"widgets_values":[6,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":81,"type":"nsInteger","pos":[-433,1004],"size":{"0":210,"1":140},"flags":{},"order":2,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[101],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"81","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"81","values":768,"cacheable":true},"timestamp":"12/16/24, 09:01:49.658 PM"}},"widgets_values":[768,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":83,"type":"nsInteger","pos":[-433,1289],"size":{"0":210,"1":140},"flags":{},"order":3,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[100],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"83","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"83","values":128,"cacheable":true},"timestamp":"12/16/24, 09:01:49.759 PM"}},"widgets_values":[128,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":85,"type":"nsInteger","pos":[-412,1563],"size":{"0":210,"1":140},"flags":{},"order":4,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[99],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"85","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"85","values":50256,"cacheable":true},"timestamp":"12/16/24, 09:01:49.861 PM"}},"widgets_values":[50256,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":100,"type":"PassThrough","pos":[-124,744],"size":{"0":210,"1":185},"flags":{},"order":14,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":94},{"name":"ignored_input","type":"*","link":106}],"outputs":[{"name":"*","type":"*","links":[102],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"100","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"100","values":6,"cacheable":true},"timestamp":"12/16/24, 09:01:50.872 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":101,"type":"PassThrough","pos":[-141,1014],"size":{"0":210,"1":185},"flags":{},"order":16,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":101},{"name":"ignored_input","type":"*","link":107}],"outputs":[{"name":"*","type":"*","links":[103],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"101","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"101","values":768,"cacheable":true},"timestamp":"12/16/24, 09:01:51.079 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":102,"type":"PassThrough","pos":[-141,1302],"size":{"0":210,"1":185},"flags":{},"order":18,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":100},{"name":"ignored_input","type":"*","link":108}],"outputs":[{"name":"*","type":"*","links":[104],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"102","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"102","values":128,"cacheable":true},"timestamp":"12/16/24, 09:01:51.275 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":103,"type":"PassThrough","pos":[-139,1561],"size":{"0":210,"1":185},"flags":{},"order":20,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":99},{"name":"ignored_input","type":"*","link":109}],"outputs":[{"name":"*","type":"*","links":[105],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"103","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"103","values":50256,"cacheable":true},"timestamp":"12/16/24, 09:01:51.477 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":75,"type":"nsInteger","pos":[-410,208],"size":{"0":210,"1":140},"flags":{},"order":5,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[61],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"75","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"75","values":50304,"cacheable":true},"timestamp":"12/16/24, 09:01:49.457 PM"}},"widgets_values":[50304,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":82,"type":"MemoryWrite","pos":[137,1293],"size":{"0":210,"1":185},"flags":{},"order":19,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":104}],"outputs":[{"name":"*","type":"*","links":[109],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"82","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"82","values":{"key":"block_size","value":128},"cacheable":true},"timestamp":"12/16/24, 09:01:51.376 PM"}},"widgets_values":["block_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":80,"type":"MemoryWrite","pos":[140,1012],"size":{"0":210,"1":185},"flags":{},"order":17,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":103}],"outputs":[{"name":"*","type":"*","links":[108],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"80","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"80","values":{"key":"model_dim","value":768},"cacheable":true},"timestamp":"12/16/24, 09:01:51.174 PM"}},"widgets_values":["model_dim","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":78,"type":"MemoryWrite","pos":[144,738],"size":{"0":210,"1":185},"flags":{},"order":15,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":102}],"outputs":[{"name":"*","type":"*","links":[107],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"78","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"78","values":{"key":"num_heads","value":6},"cacheable":true},"timestamp":"12/16/24, 09:01:50.973 PM"}},"widgets_values":["num_heads","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":76,"type":"MemoryWrite","pos":[143,469],"size":{"0":210,"1":185},"flags":{},"order":13,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":93}],"outputs":[{"name":"*","type":"*","links":[106],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"76","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"76","values":{"key":"num_layers","value":12},"cacheable":true},"timestamp":"12/16/24, 09:01:50.771 PM"}},"widgets_values":["num_layers","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":84,"type":"MemoryWrite","pos":[130,1573],"size":{"0":210,"1":185},"flags":{},"order":21,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":105}],"outputs":[{"name":"*","type":"*","links":[136],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"84","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"84","values":{"key":"vocab_max_size","value":50256},"cacheable":true},"timestamp":"12/16/24, 09:01:51.578 PM"}},"widgets_values":["vocab_max_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":120,"type":"PassThrough","pos":[1027,753],"size":{"0":210,"1":185},"flags":{},"order":22,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":137},{"name":"ignored_input","type":"*","link":136}],"outputs":[{"name":"*","type":"*","links":[138],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"120","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"120","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"],"cacheable":true},"timestamp":"12/16/24, 09:01:51.680 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":121,"type":"ValuePath","pos":[3488,449],"size":{"0":249.9785919189453,"1":185},"flags":{},"order":25,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"object","type":"*","link":149},{"name":"value_path","type":"*","link":null}],"outputs":[{"name":"*","type":"*","links":[140],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"121","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"121","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"],"cacheable":true},"timestamp":"12/16/24, 09:02:19.344 PM"}},"widgets_values":["","node_inputs",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":118,"type":"nsArrayAppend","pos":[4758,661],"size":{"0":210,"1":224.7087860107422},"flags":{},"order":45,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"array","type":"array","link":140},{"name":"element","type":"*","link":152}],"outputs":[{"name":"array","type":"array","links":[146],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"118","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"array","name":"array","node_id":"118","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"],"cacheable":true},"timestamp":"12/16/24, 09:02:21.698 PM"}},"widgets_values":[null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":133,"type":"CastedLinear","pos":[3655,1971],"size":{"0":210,"1":230},"flags":{},"order":40,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":166},{"name":"out_features","type":"number","link":167},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[165],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"133","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"133","values":"CastedLinearModule(in_features=3072, out_features=768, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:21.151 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":104,"type":"WhileLoop","pos":[1330,493],"size":{"0":226.70957946777344,"1":372.1649475097656},"flags":{},"order":23,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"condition_key","type":"string","link":133},{"name":"node_inputs","type":"*","link":138}],"outputs":[{"name":"loop","type":"control_flow","links":[119,128,149],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"104","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"control_flow","name":"loop","node_id":"104","values":{"node_inputs":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"]},"cacheable":false},"timestamp":"12/16/24, 09:02:21.807 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":111,"type":"MemoryRead","pos":[1853,566],"size":{"0":210,"1":140},"flags":{},"order":26,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":123}],"outputs":[{"name":"*","type":"*","links":[124],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"111","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"111","values":1,"cacheable":true},"timestamp":"12/16/24, 09:02:19.453 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":110,"type":"Subtract","pos":[2124,560],"size":{"0":210,"1":185},"flags":{},"order":27,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"a","type":"number","link":124},{"name":"b","type":"number","link":null}],"outputs":[{"name":"result","type":"number","links":[125],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"110","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"number","name":"result","node_id":"110","values":0,"cacheable":true},"timestamp":"12/16/24, 09:02:19.555 PM"}},"widgets_values":[0,1,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":109,"type":"MemoryWrite","pos":[2421,567],"size":{"0":210,"1":185},"flags":{},"order":28,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":126},{"name":"value","type":"*","link":125}],"outputs":[{"name":"*","type":"*","links":[184],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"109","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"109","values":{"key":"layers_needed","value":0},"cacheable":true},"timestamp":"12/16/24, 09:02:19.667 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":140,"type":"PassThrough","pos":[1365,1164],"size":{"0":210,"1":185},"flags":{},"order":29,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":184}],"outputs":[{"name":"*","type":"*","links":[185,187],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"140","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"140","values":"num_heads","cacheable":true},"timestamp":"12/16/24, 09:02:19.767 PM"}},"widgets_values":["num_heads","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":131,"type":"MemoryRead","pos":[1655,1170],"size":{"0":210,"1":140},"flags":{},"order":31,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":187}],"outputs":[{"name":"*","type":"*","links":[156,168],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"131","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"131","values":6,"cacheable":true},"timestamp":"12/16/24, 09:02:19.981 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":141,"type":"PassThrough","pos":[1374,1481],"size":{"0":210,"1":185},"flags":{},"order":30,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":185}],"outputs":[{"name":"*","type":"*","links":[186],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"141","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"141","values":"model_dim","cacheable":true},"timestamp":"12/16/24, 09:02:19.988 PM"}},"widgets_values":["model_dim","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":134,"type":"Divide","pos":[2083,1247],"size":{"0":210,"1":185},"flags":{},"order":34,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"numerator","type":"number","link":169},{"name":"denominator","type":"number","link":168}],"outputs":[{"name":"result","type":"number","links":[170],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"134","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"number","name":"result","node_id":"134","values":128,"cacheable":true},"timestamp":"12/16/24, 09:02:20.348 PM"}},"widgets_values":[1,1,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":137,"type":"CastedLinear","pos":[2472,848],"size":{"0":210,"1":230},"flags":{},"order":35,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":175},{"name":"out_features","type":"number","link":176},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[181],"slot_index":0}],"title":"CastedLinear (Queries)","properties":{"evaluation_action":{"node_id":"137","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"137","values":"CastedLinearModule(in_features=768, out_features=768, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:20.468 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":138,"type":"CastedLinear","pos":[2485,1126],"size":{"0":210,"1":230},"flags":{},"order":37,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":179},{"name":"out_features","type":"number","link":180},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[182],"slot_index":0}],"title":"CastedLinear (Keys)","properties":{"evaluation_action":{"node_id":"138","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"138","values":"CastedLinearModule(in_features=768, out_features=768, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:20.612 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":139,"type":"CastedLinear","pos":[2480,1405],"size":{"0":210,"1":230},"flags":{},"order":36,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":177},{"name":"out_features","type":"number","link":178},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[183],"slot_index":0}],"title":"CastedLinear (Values)","properties":{"evaluation_action":{"node_id":"139","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"139","values":"CastedLinearModule(in_features=768, out_features=768, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:20.721 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":136,"type":"RotaryEmbedding","pos":[3281,1087],"size":{"0":210,"1":185},"flags":{},"order":41,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"dim","type":"number","link":170},{"name":"base","type":"number","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[171],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"136","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"136","values":"RotaryEmbeddingModule()","cacheable":false},"timestamp":"12/16/24, 09:02:21.257 PM"}},"widgets_values":["",10000,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":130,"type":"MemoryRead","pos":[1670,1488],"size":{"0":210,"1":140},"flags":{},"order":32,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":186}],"outputs":[{"name":"*","type":"*","links":[155,157,158,163,167,169,175,176,177,178,179,180,188,190],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"130","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"130","values":768,"cacheable":true},"timestamp":"12/16/24, 09:02:20.148 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":132,"type":"Multiply","pos":[3323,1725],"size":{"0":210,"1":185},"flags":{},"order":33,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"a","type":"number","link":158},{"name":"b","type":"number","link":null}],"outputs":[{"name":"result","type":"number","links":[161,166],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"132","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"number","name":"result","node_id":"132","values":3072,"cacheable":true},"timestamp":"12/16/24, 09:02:20.268 PM"}},"widgets_values":[1,4,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":127,"type":"CastedLinear","pos":[3666,1606],"size":{"0":210,"1":230},"flags":{},"order":39,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":163},{"name":"out_features","type":"number","link":161},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[164],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"127","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"127","values":"CastedLinearModule(in_features=768, out_features=3072, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:20.985 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":124,"type":"TransformerBlock","pos":[4360,903],"size":{"0":270.3999938964844,"1":306.1888427734375},"flags":{},"order":44,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"causal_self_attention","type":"*","link":154},{"name":"multi_layer_perceptron","type":"*","link":150}],"outputs":[{"name":"nn.Module","type":"*","links":[152],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"124","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"124","values":"BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","cacheable":false},"timestamp":"12/16/24, 09:02:21.586 PM"}},"widgets_values":[null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":126,"type":"MultiLayerPerceptron","pos":[3949,1848],"size":{"0":270.3999938964844,"1":180},"flags":{},"order":42,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"dim","type":"number","link":155},{"name":"casted_fully_connected","type":"*","link":164},{"name":"casted_up_projection","type":"*","link":165}],"outputs":[{"name":"nn.Module","type":"*","links":[150],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"126","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"126","values":"MLPModule(\n  (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n  (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n)","cacheable":false},"timestamp":"12/16/24, 09:02:21.367 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":145,"type":"CastedLinear","pos":[2157,3019],"size":{"0":210,"1":230},"flags":{},"order":63,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":206},{"name":"out_features","type":"number","link":207},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[194],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"145","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"145","values":"CastedLinearModule(in_features=768, out_features=50304, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:26.407 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":144,"type":"ValueEmbedding","pos":[2156,2743],"size":{"0":210,"1":185},"flags":{},"order":62,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"vocab_size","type":"number","link":204},{"name":"model_dim","type":"number","link":205}],"outputs":[{"name":"nn.Module","type":"*","links":[193],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"144","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"144","values":"ValueEmbeddingModule(\n  (embed): ModuleList(\n    (0-5): 6 x Embedding(50304, 768)\n  )\n)","cacheable":false},"timestamp":"12/16/24, 09:02:25.913 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":108,"type":"PassThrough","pos":[1608,552],"size":{"0":210,"1":185},"flags":{},"order":24,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":122},{"name":"ignored_input","type":"*","link":119}],"outputs":[{"name":"*","type":"*","links":[123],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"108","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"108","values":"layers_needed","cacheable":true},"timestamp":"12/16/24, 09:02:19.237 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":122,"type":"ValuePath","pos":[1977,2313],"size":[486.16817382812496,322.4666699218751],"flags":{},"order":47,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"object","type":"*","link":199},{"name":"value_path","type":"*","link":null}],"outputs":[{"name":"*","type":"*","links":[192],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"122","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"122","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"],"cacheable":true},"timestamp":"12/16/24, 09:02:22.052 PM"}},"widgets_values":["","WhileLoop.values.node_inputs",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":150,"type":"PassThrough","pos":[1421,2931],"size":{"0":210,"1":185},"flags":{},"order":48,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":200}],"outputs":[{"name":"*","type":"*","links":[201],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"150","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"150","values":"vocab_size","cacheable":true},"timestamp":"12/16/24, 09:02:22.161 PM"}},"widgets_values":["vocab_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":146,"type":"MemoryRead","pos":[1696,2935],"size":{"0":210,"1":140},"flags":{},"order":55,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":201}],"outputs":[{"name":"*","type":"*","links":[204,207],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"146","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"146","values":50304,"cacheable":true},"timestamp":"12/16/24, 09:02:23.029 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":147,"type":"MemoryRead","pos":[1738,3193],"size":{"0":210,"1":140},"flags":{},"order":56,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":203}],"outputs":[{"name":"*","type":"*","links":[205,206,208],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"147","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"147","values":768,"cacheable":true},"timestamp":"12/16/24, 09:02:23.148 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":151,"type":"PassThrough","pos":[1434,3202],"size":{"0":210,"1":185},"flags":{},"order":49,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":202}],"outputs":[{"name":"*","type":"*","links":[203],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"151","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"151","values":"model_dim","cacheable":true},"timestamp":"12/16/24, 09:02:22.281 PM"}},"widgets_values":["model_dim","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":153,"type":"PassThrough","pos":[1438,3465],"size":{"0":210,"1":185},"flags":{},"order":50,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":211}],"outputs":[{"name":"*","type":"*","links":[209],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"153","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"153","values":"num_heads","cacheable":true},"timestamp":"12/16/24, 09:02:22.458 PM"}},"widgets_values":["num_heads","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":152,"type":"MemoryRead","pos":[1734,3450],"size":{"0":210,"1":140},"flags":{},"order":57,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":209}],"outputs":[{"name":"*","type":"*","links":[213],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"152","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"152","values":6,"cacheable":true},"timestamp":"12/16/24, 09:02:23.264 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":155,"type":"PassThrough","pos":[1443,3749],"size":{"0":210,"1":185},"flags":{},"order":51,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":212}],"outputs":[{"name":"*","type":"*","links":[210],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"155","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"155","values":"vocab_size","cacheable":true},"timestamp":"12/16/24, 09:02:22.552 PM"}},"widgets_values":["vocab_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":157,"type":"PassThrough","pos":[1446,4020],"size":{"0":210,"1":185},"flags":{},"order":52,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":216}],"outputs":[{"name":"*","type":"*","links":[214],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"157","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"157","values":"vocab_size_max","cacheable":true},"timestamp":"12/16/24, 09:02:22.663 PM"}},"widgets_values":["vocab_size_max","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":159,"type":"PassThrough","pos":[1437,4314],"size":{"0":210,"1":185},"flags":{},"order":53,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":217}],"outputs":[{"name":"*","type":"*","links":[215],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"159","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"159","values":"block_size","cacheable":true},"timestamp":"12/16/24, 09:02:22.798 PM"}},"widgets_values":["block_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":112,"type":"EndWhileLoop","pos":[884,2317],"size":{"0":352.98028564453125,"1":347.6124267578125},"flags":{},"order":46,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"WhileLoop","type":"control_flow","link":128},{"name":"node_inputs","type":"*","link":146}],"outputs":[{"name":"*","type":"*","links":[199,200,202,211,212,216,217,219],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"112","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"112","values":{"node_inputs":{"kind":"*","name":"node_inputs","node_id":"118","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"]},"WhileLoop":{"kind":"control_flow","name":"WhileLoop","node_id":"104","values":{"node_inputs":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"]}}},"cacheable":true},"timestamp":"12/16/24, 09:02:21.931 PM"}},"widgets_values":[null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":161,"type":"PassThrough","pos":[1424,4620],"size":{"0":210,"1":185},"flags":{},"order":54,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"*","link":null},{"name":"ignored_input","type":"*","link":219}],"outputs":[{"name":"*","type":"*","links":[218],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"161","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"161","values":"num_layers","cacheable":true},"timestamp":"12/16/24, 09:02:22.911 PM"}},"widgets_values":["num_layers","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":160,"type":"MemoryRead","pos":[1714,4628],"size":{"0":210,"1":140},"flags":{},"order":61,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":218}],"outputs":[{"name":"*","type":"*","links":[220],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"160","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"160","values":12,"cacheable":true},"timestamp":"12/16/24, 09:02:23.702 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":158,"type":"MemoryRead","pos":[1730,4303],"size":{"0":210,"1":140},"flags":{},"order":60,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":215}],"outputs":[{"name":"*","type":"*","links":[221],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"158","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"158","values":128,"cacheable":true},"timestamp":"12/16/24, 09:02:23.592 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":156,"type":"MemoryRead","pos":[1736,4008],"size":{"0":210,"1":140},"flags":{},"order":59,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":214}],"outputs":[{"name":"*","type":"*","links":[222],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"156","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"156","values":null,"cacheable":true},"timestamp":"12/16/24, 09:02:23.486 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":154,"type":"MemoryRead","pos":[1732,3729],"size":{"0":210,"1":140},"flags":{},"order":58,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":210}],"outputs":[{"name":"*","type":"*","links":[223],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"154","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"154","values":50304,"cacheable":true},"timestamp":"12/16/24, 09:02:23.375 PM"}},"widgets_values":["",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":129,"type":"CausalSelfAttention","pos":[3659,812],"size":{"0":270.072265625,"1":306.0899963378906},"flags":{},"order":43,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"dim","type":"number","link":157},{"name":"num_heads","type":"number","link":156},{"name":"query_linear","type":"*","link":181},{"name":"keys_linear","type":"*","link":182},{"name":"values_linear","type":"*","link":183},{"name":"rotary","type":"*","link":171},{"name":"context_linear","type":"*","link":191}],"outputs":[{"name":"nn.Module","type":"*","links":[154],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"129","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"129","values":"CausalSelfAttentionModule(\n  (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  (rotary): RotaryEmbeddingModule()\n  (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n)","cacheable":false},"timestamp":"12/16/24, 09:02:21.476 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":142,"type":"CastedLinear","pos":[3271,1367],"size":{"0":210,"1":230},"flags":{},"order":38,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"in_features","type":"number","link":188},{"name":"out_features","type":"number","link":190},{"name":"bias","type":"boolean","link":null}],"outputs":[{"name":"nn.Module","type":"*","links":[191],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"142","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"142","values":"CastedLinearModule(in_features=768, out_features=768, bias=False)","cacheable":false},"timestamp":"12/16/24, 09:02:20.833 PM"}},"widgets_values":["","",false,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":74,"type":"MemoryWrite","pos":[155,184],"size":{"0":210,"1":185},"flags":{},"order":9,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":null},{"name":"value","type":"*","link":61}],"outputs":[{"name":"*","type":"*","links":[78],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"74","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"74","values":{"key":"vocab_size","value":50304},"cacheable":true},"timestamp":"12/16/24, 09:01:50.366 PM"}},"widgets_values":["vocab_size","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":143,"type":"GPT2","pos":[2736,3303],"size":[479.65174839843803,779.6686401562501],"flags":{},"order":64,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"block_list","type":"*","link":192},{"name":"value_embeds","type":"*","link":193,"slot_index":3},{"name":"language_model_head","type":"*","link":194,"slot_index":4},{"name":"num_heads","type":"number","link":213,"slot_index":5},{"name":"model_dim","type":"number","link":208,"slot_index":6},{"name":"block_size","type":"number","link":221,"slot_index":7},{"name":"vocab_size","type":"number","link":223,"slot_index":8},{"name":"vocab_max_size","type":"number","link":222,"slot_index":9},{"name":"num_layers","type":"number","link":220,"slot_index":10}],"outputs":[{"name":"nn.Module","type":"*","links":[],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"143","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"nn.Module","node_id":"143","values":"GPT2Module(\n  (embed): Embedding(50304, 768)\n  (blocks): ModuleList(\n    (0-11): 12 x BlockModule(\n      (causal_self_attention): CausalSelfAttentionModule(\n        (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n        (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n        (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n        (rotary): RotaryEmbeddingModule()\n        (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n      )\n      (multi_layer_perceptron): MLPModule(\n        (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n        (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n      )\n    )\n  )\n  (value_embeds): ValueEmbeddingModule(\n    (embed): ModuleList(\n      (0-5): 6 x Embedding(50304, 768)\n    )\n  )\n  (lm_head): CastedLinearModule(in_features=768, out_features=50304, bias=False)\n)","cacheable":false},"timestamp":"12/16/24, 09:02:26.824 PM"}},"widgets_values":["","","","","","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":119,"type":"nsArray","pos":[604,807],"size":{"0":210,"1":140},"flags":{},"order":8,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"initial_data","type":"array","link":null}],"outputs":[{"name":"array","type":"*","links":[137],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"119","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"array","node_id":"119","values":["BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)","BlockModule(\n  (causal_self_attention): CausalSelfAttentionModule(\n    (casted_queries): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_keys): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (casted_values): CastedLinearModule(in_features=768, out_features=768, bias=False)\n    (rotary): RotaryEmbeddingModule()\n    (casted_projection): CastedLinearModule(in_features=768, out_features=768, bias=False)\n  )\n  (multi_layer_perceptron): MLPModule(\n    (casted_fully_connected): CastedLinearModule(in_features=768, out_features=3072, bias=False)\n    (casted_up_projection): CastedLinearModule(in_features=3072, out_features=768, bias=False)\n  )\n)"],"cacheable":true},"timestamp":"12/16/24, 09:01:50.264 PM"}},"widgets_values":["[]",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":106,"type":"nsString","pos":[554,116],"size":{"0":210,"1":140},"flags":{},"order":6,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10],"slot_index":0},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"text","type":"*","link":null}],"outputs":[{"name":"*","type":"*","links":[116,122,126],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"106","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"106","values":"layers_needed","cacheable":true},"timestamp":"12/16/24, 09:01:50.062 PM"}},"widgets_values":["layers_needed",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":105,"type":"MemoryWrite","pos":[800,338],"size":{"0":210,"1":185},"flags":{},"order":10,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"key","type":"*","link":116},{"name":"value","type":"*","link":117}],"outputs":[{"name":"*","type":"*","links":[132],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"105","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"105","values":{"key":"layers_needed","value":12},"cacheable":true},"timestamp":"12/16/24, 09:01:50.467 PM"}},"widgets_values":["","",null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":107,"type":"nsInteger","pos":[545,346],"size":{"0":210,"1":140},"flags":{},"order":7,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"value","type":"number","link":null}],"outputs":[{"name":"*","type":"*","links":[117],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"107","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"107","values":12,"cacheable":true},"timestamp":"12/16/24, 09:01:50.163 PM"}},"widgets_values":[12,null],"color":"#B8D982","bgcolor":"#B8D982"},{"id":114,"type":"ValuePath","pos":[1059,445],"size":{"0":210,"1":185},"flags":{},"order":12,"mode":0,"inputs":[{"name":"in_rules","type":"rule_group","link":null,"pos":[10,10]},{"name":"out_rules","type":"rule_group","link":null,"pos":[10,25]},{"name":"object","type":"*","link":132},{"name":"value_path","type":"*","link":null}],"outputs":[{"name":"*","type":"*","links":[133],"slot_index":0}],"properties":{"evaluation_action":{"node_id":"114","runtime_action":0,"destination_node_id":""},"result":{"prompt_id":"-OEHZ7uL9RplSLVSVWYN","result":{"kind":"*","name":"*","node_id":"114","values":"layers_needed","cacheable":true},"timestamp":"12/16/24, 09:01:50.669 PM"}},"widgets_values":["","key",null],"color":"#B8D982","bgcolor":"#B8D982"}],"links":[[61,75,0,74,3,"*"],[78,74,0,93,3,"*"],[92,99,0,93,2,"*"],[93,93,0,76,3,"*"],[94,79,0,100,2,"*"],[99,85,0,103,2,"*"],[100,83,0,102,2,"*"],[101,81,0,101,2,"*"],[102,100,0,78,3,"*"],[103,101,0,80,3,"*"],[104,102,0,82,3,"*"],[105,103,0,84,3,"*"],[106,76,0,100,3,"*"],[107,78,0,101,3,"*"],[108,80,0,102,3,"*"],[109,82,0,103,3,"*"],[116,106,0,105,2,"*"],[117,107,0,105,3,"*"],[119,104,0,108,3,"*"],[122,106,0,108,2,"*"],[123,108,0,111,2,"*"],[124,111,0,110,2,"number"],[125,110,0,109,3,"*"],[126,106,0,109,2,"*"],[128,104,0,112,2,"control_flow"],[132,105,0,114,2,"*"],[133,114,0,104,2,"string"],[136,84,0,120,3,"*"],[137,119,0,120,2,"*"],[138,120,0,104,3,"*"],[140,121,0,118,2,"array"],[146,118,0,112,3,"*"],[149,104,0,121,2,"*"],[150,126,0,124,3,"*"],[152,124,0,118,3,"*"],[154,129,0,124,2,"*"],[155,130,0,126,2,"number"],[156,131,0,129,3,"number"],[157,130,0,129,2,"number"],[158,130,0,132,2,"number"],[161,132,0,127,3,"number"],[163,130,0,127,2,"number"],[164,127,0,126,3,"*"],[165,133,0,126,4,"*"],[166,132,0,133,2,"number"],[167,130,0,133,3,"number"],[168,131,0,134,3,"number"],[169,130,0,134,2,"number"],[170,134,0,136,2,"number"],[171,136,0,129,7,"*"],[175,130,0,137,2,"number"],[176,130,0,137,3,"number"],[177,130,0,139,2,"number"],[178,130,0,139,3,"number"],[179,130,0,138,2,"number"],[180,130,0,138,3,"number"],[181,137,0,129,4,"*"],[182,138,0,129,5,"*"],[183,139,0,129,6,"*"],[184,109,0,140,3,"*"],[185,140,0,141,3,"*"],[186,141,0,130,2,"*"],[187,140,0,131,2,"*"],[188,130,0,142,2,"number"],[190,130,0,142,3,"number"],[191,142,0,129,8,"*"],[192,122,0,143,2,"*"],[193,144,0,143,3,"*"],[194,145,0,143,4,"*"],[199,112,0,122,2,"*"],[200,112,0,150,3,"*"],[201,150,0,146,2,"*"],[202,112,0,151,3,"*"],[203,151,0,147,2,"*"],[204,146,0,144,2,"number"],[205,147,0,144,3,"number"],[206,147,0,145,2,"number"],[207,146,0,145,3,"number"],[208,147,0,143,6,"number"],[209,153,0,152,2,"*"],[210,155,0,154,2,"*"],[211,112,0,153,3,"*"],[212,112,0,155,3,"*"],[213,152,0,143,5,"number"],[214,157,0,156,2,"*"],[215,159,0,158,2,"*"],[216,112,0,157,3,"*"],[217,112,0,159,3,"*"],[218,161,0,160,2,"*"],[219,112,0,161,3,"*"],[220,160,0,143,10,"number"],[221,158,0,143,7,"number"],[222,156,0,143,9,"number"],[223,154,0,143,8,"number"]],"groups":[],"config":{},"extra":{},"version":0.4,"NeoScaffoldVersion":0.1,"checksum":"45AagZLvpa6HHSJ3cqL+2w/wLEh+O3NG/mP2Zz3AOnY="}